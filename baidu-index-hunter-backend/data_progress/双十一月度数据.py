import pandas as pd
import numpy as np
from datetime import datetime
import os
from itertools import product


class MonthlyDataAggregator:
    def __init__(self, input_file_path, output_dir="./output"):
        """
        åˆå§‹åŒ–æœˆåº¦æ•°æ®ç»Ÿè®¡å™¨

        Args:
            input_file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
        """
        self.input_file_path = input_file_path
        self.output_dir = output_dir

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        # åˆ—åæ˜ å°„
        self.column_mapping = {
            'å…³é”®è¯': 'keyword',
            'åŸå¸‚ä»£ç ': 'city_code',
            'åŸå¸‚': 'city_name',
            'æ—¥æœŸ': 'date',
            'æ•°æ®ç±»å‹': 'data_type',
            'æ•°æ®é—´éš”(å¤©)': 'data_interval',
            'æ‰€å±å¹´ä»½': 'year',
            'PC+ç§»åŠ¨æŒ‡æ•°': 'pc_mobile_index',
            'ç§»åŠ¨æŒ‡æ•°': 'mobile_index',
            'PCæŒ‡æ•°': 'pc_index',
            'çˆ¬å–æ—¶é—´': 'crawl_time'
        }

    def load_data(self):
        """åŠ è½½æ•°æ®æ–‡ä»¶"""
        try:
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è¯»å–æ–¹å¼
            if self.input_file_path.endswith('.csv'):
                df = pd.read_csv(self.input_file_path, encoding='utf-8')
            elif self.input_file_path.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(self.input_file_path)
            else:
                # å°è¯•ä»¥åˆ¶è¡¨ç¬¦åˆ†éš”çš„æ–‡æœ¬æ–‡ä»¶è¯»å–
                df = pd.read_csv(self.input_file_path, sep='\t', encoding='utf-8')

            print(f"æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(df)} è¡Œ")
            return df

        except Exception as e:
            print(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return None

    def preprocess_data(self, df):
        """é¢„å¤„ç†æ•°æ®"""
        try:
            # é‡å‘½ååˆ—ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if 'å…³é”®è¯' in df.columns:
                df = df.rename(columns=self.column_mapping)

            # è½¬æ¢æ—¥æœŸæ ¼å¼
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'], errors='coerce')
            else:
                print("æœªæ‰¾åˆ°æ—¥æœŸåˆ—")
                return None

            # åˆ›å»ºå¹´æœˆåˆ—
            df['year_month'] = df['date'].dt.strftime('%Y-%m')
            df['year'] = df['date'].dt.year
            df['month'] = df['date'].dt.month

            # è½¬æ¢æ•°å€¼åˆ—ï¼Œå¤„ç†ç©ºå€¼
            numeric_columns = ['pc_mobile_index', 'mobile_index', 'pc_index']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')

            # åˆ é™¤æ— æ•ˆæ—¥æœŸçš„è¡Œ
            # df = df.dropna(subset=['date'])

            # åˆ é™¤æ‰€æœ‰æŒ‡æ•°éƒ½ä¸ºç©ºçš„è¡Œ
            # df = df.dropna(subset=numeric_columns, how='all')

            print(f"æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œæœ‰æ•ˆæ•°æ® {len(df)} è¡Œ")
            print(f"æ—¥æœŸèŒƒå›´: {df['date'].min()} åˆ° {df['date'].max()}")

            return df

        except Exception as e:
            print(f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            return None

    def create_complete_monthly_template(self, df):
        """åˆ›å»ºå®Œæ•´çš„æœˆåº¦æ¨¡æ¿ï¼Œä¸ºæ¯ä¸ªå…³é”®è¯-åŸå¸‚ç»„åˆåˆ›å»ºå…¶å„è‡ªçš„å®Œæ•´æ—¶é—´èŒƒå›´"""
        try:
            # è·å–æ¯ä¸ªå…³é”®è¯-åŸå¸‚ç»„åˆçš„æ—¶é—´èŒƒå›´
            combo_date_ranges = df.groupby(['keyword', 'city_code', 'city_name'])['date'].agg(['min', 'max']).reset_index()
            
            print(f"åˆ›å»ºå®Œæ•´æœˆåº¦æ¨¡æ¿:")
            print(f"  å…³é”®è¯-åŸå¸‚ç»„åˆæ•°: {len(combo_date_ranges)}")
            
            # åˆ›å»ºå®Œæ•´çš„ç»„åˆ
            complete_combinations = []
            total_months = 0
            
            for _, combo in combo_date_ranges.iterrows():
                # ä¸ºæ¯ä¸ªç»„åˆåˆ›å»ºä»å…¶æœ€å°æ—¥æœŸåˆ°æœ€å¤§æ—¥æœŸçš„æ‰€æœ‰æœˆä»½
                min_date = combo['min'].replace(day=1)  # æœˆåˆ
                max_date = combo['max'].replace(day=1)  # æœˆåˆ
                
                # åˆ›å»ºè¯¥ç»„åˆçš„æœˆä»½èŒƒå›´
                date_range = pd.date_range(start=min_date, end=max_date, freq='MS')
                year_months = [date.strftime('%Y-%m') for date in date_range]
                
                # ä¸ºè¯¥ç»„åˆæ·»åŠ æ‰€æœ‰æœˆä»½
                for year_month in year_months:
                    complete_combinations.append({
                        'keyword': combo['keyword'],
                        'city_code': combo['city_code'],
                        'city_name': combo['city_name'],
                        'year_month': year_month,
                        'year': int(year_month.split('-')[0]),
                        'month': int(year_month.split('-')[1])
                    })
                
                total_months += len(year_months)
            
            template_df = pd.DataFrame(complete_combinations)
            
            print(f"  ç†è®ºè®°å½•æ•°: {total_months}")
            print(f"  å®é™…åˆ›å»ºæ¨¡æ¿è®°å½•æ•°: {len(template_df)}")
            
            # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
            if len(template_df) > 0:
                earliest_month = template_df['year_month'].min()
                latest_month = template_df['year_month'].max()
                print(f"  æ•´ä½“æ—¶é—´èŒƒå›´: {earliest_month} åˆ° {latest_month}")
                
                # æ˜¾ç¤ºæ¯ä¸ªå…³é”®è¯çš„ç»Ÿè®¡
                keyword_stats = template_df.groupby('keyword')['year_month'].agg(['min', 'max', 'count']).reset_index()
                keyword_stats.columns = ['keyword', 'start_month', 'end_month', 'month_count']
                print(f"  å„å…³é”®è¯æ—¶é—´è·¨åº¦:")
                for _, row in keyword_stats.iterrows():
                    print(f"    {row['keyword']}: {row['start_month']} åˆ° {row['end_month']} ({row['month_count']} ä¸ªæœˆ)")
            
            return template_df
            
        except Exception as e:
            print(f"åˆ›å»ºæœˆåº¦æ¨¡æ¿å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def aggregate_monthly_data(self, df):
        """æŒ‰æœˆåº¦èšåˆæ•°æ®"""
        try:
            # åˆ†ç»„åˆ—
            group_columns = ['keyword', 'city_code', 'city_name', 'year_month', 'year', 'month']

            # æ•°å€¼åˆ—
            numeric_columns = ['pc_mobile_index', 'mobile_index', 'pc_index']

            # èšåˆç»Ÿè®¡
            agg_dict = {}

            # ä¸ºæ¯ä¸ªæ•°å€¼åˆ—åˆ›å»ºç»Ÿè®¡é‡
            for col in numeric_columns:
                if col in df.columns:
                    agg_dict[col] = ['sum', 'mean', 'count', 'min', 'max', 'std']

            # æ‰§è¡Œèšåˆ
            monthly_data = df.groupby(group_columns).agg(agg_dict).reset_index()

            # å¤„ç†å¤šçº§åˆ—å
            new_columns = []
            for col in monthly_data.columns:
                if isinstance(col, tuple) and len(col) == 2:
                    base_col, agg_type = col
                    if agg_type == 'sum':
                        new_columns.append(f'{base_col}_æœˆåº¦æ€»å’Œ')
                    elif agg_type == 'mean':
                        new_columns.append(f'{base_col}_æœˆåº¦å‡å€¼')
                    elif agg_type == 'count':
                        new_columns.append(f'{base_col}_æ•°æ®ç‚¹æ•°')
                    elif agg_type == 'min':
                        new_columns.append(f'{base_col}_æœˆåº¦æœ€å°å€¼')
                    elif agg_type == 'max':
                        new_columns.append(f'{base_col}_æœˆåº¦æœ€å¤§å€¼')
                    elif agg_type == 'std':
                        new_columns.append(f'{base_col}_æœˆåº¦æ ‡å‡†å·®')
                    else:
                        new_columns.append(f'{base_col}_{agg_type}')
                else:
                    new_columns.append(col)

            monthly_data.columns = new_columns

            # å¯¹æ•°å€¼åˆ—è¿›è¡Œå››èˆäº”å…¥
            for col in monthly_data.columns:
                if any(suffix in col for suffix in ['_å‡å€¼', '_æ ‡å‡†å·®']):
                    monthly_data[col] = monthly_data[col].round(2)

            print(f"æœˆåº¦æ•°æ®èšåˆå®Œæˆï¼Œå…± {len(monthly_data)} è¡Œ")
            
            return monthly_data

        except Exception as e:
            print(f"æœˆåº¦æ•°æ®èšåˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def create_complete_monthly_data(self, df):
        """åˆ›å»ºå®Œæ•´çš„æœˆåº¦æ•°æ®ï¼ŒåŒ…å«ç¼ºå¤±æœˆä»½çš„è®°å½•"""
        try:
            # å…ˆè¿›è¡Œæ­£å¸¸çš„æœˆåº¦èšåˆ
            monthly_data = self.aggregate_monthly_data(df)
            if monthly_data is None:
                return None
            
            # åˆ›å»ºå®Œæ•´çš„æœˆåº¦æ¨¡æ¿
            template_df = self.create_complete_monthly_template(df)
            if template_df is None:
                return None
            
            print(f"å‡†å¤‡åˆå¹¶æ•°æ®:")
            print(f"  æ¨¡æ¿æ•°æ®å½¢çŠ¶: {template_df.shape}")
            print(f"  èšåˆæ•°æ®å½¢çŠ¶: {monthly_data.shape}")
            
            # æ£€æŸ¥åˆ—å
            print(f"  æ¨¡æ¿åˆ—å: {template_df.columns.tolist()}")
            print(f"  èšåˆæ•°æ®åˆ—å: {monthly_data.columns.tolist()}")
            
            # ç¡®ä¿åˆ—ååŒ¹é… - æ£€æŸ¥monthly_dataä¸­çš„åˆ—åæ˜¯å¦ä¸æ¨¡æ¿åŒ¹é…
            # å¦‚æœmonthly_dataä¸­çš„åˆ—åä¸æ˜¯é¢„æœŸçš„æ ¼å¼ï¼Œéœ€è¦é‡å‘½å
            if 'keyword_' in monthly_data.columns:
                # åˆ—åå¯èƒ½æœ‰åç¼€ï¼Œéœ€è¦é‡å‘½å
                column_mapping = {
                    'keyword_': 'keyword',
                    'city_code_': 'city_code',
                    'city_name_': 'city_name',
                    'year_month_': 'year_month',
                    'year_': 'year',
                    'month_': 'month'
                }
                monthly_data = monthly_data.rename(columns=column_mapping)
                print(f"  å·²é‡å‘½ååˆ—ï¼Œç°åœ¨èšåˆæ•°æ®åˆ—å: {monthly_data.columns.tolist()}")
            
            # å°†èšåˆæ•°æ®ä¸æ¨¡æ¿åˆå¹¶ï¼Œç¡®ä¿æ‰€æœ‰ç»„åˆéƒ½å­˜åœ¨
            complete_monthly_data = template_df.merge(
                monthly_data, 
                on=['keyword', 'city_code', 'city_name', 'year_month', 'year', 'month'],
                how='left'
            )
            
            print(f"åˆå¹¶åæ•°æ®å½¢çŠ¶: {complete_monthly_data.shape}")
            
            # ä¸ºç¼ºå¤±çš„æ•°æ®æ·»åŠ æ ‡è¯†
            complete_monthly_data['has_data'] = complete_monthly_data['pc_mobile_index_æ•°æ®ç‚¹æ•°'].notna()
            
            # ç»Ÿè®¡ç¼ºå¤±æƒ…å†µ
            total_records = len(complete_monthly_data)
            records_with_data = complete_monthly_data['has_data'].sum()
            records_without_data = total_records - records_with_data
            
            print(f"å®Œæ•´æœˆåº¦æ•°æ®åˆ›å»ºå®Œæˆ:")
            print(f"  æ€»è®°å½•æ•°: {total_records}")
            print(f"  æœ‰æ•°æ®è®°å½•æ•°: {records_with_data}")
            print(f"  æ— æ•°æ®è®°å½•æ•°: {records_without_data}")
            print(f"  æ•°æ®è¦†ç›–ç‡: {records_with_data/total_records*100:.1f}%")
            
            return complete_monthly_data

        except Exception as e:
            print(f"åˆ›å»ºå®Œæ•´æœˆåº¦æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def analyze_data_coverage(self, df):
        """åˆ†ææ•°æ®è¦†ç›–æƒ…å†µ"""
        try:
            print("\næ•°æ®è¦†ç›–åˆ†æ:")
            print("=" * 50)
            
            # æŒ‰å…³é”®è¯-åŸå¸‚ç»„åˆåˆ†ææ—¶é—´è·¨åº¦
            combo_analysis = df.groupby(['keyword', 'city_code', 'city_name']).agg({
                'date': ['min', 'max', 'count'],
                'year_month': 'nunique'
            }).reset_index()
            
            # å±•å¹³å¤šçº§åˆ—å
            combo_analysis.columns = ['keyword', 'city_code', 'city_name', 'first_date', 'last_date', 'total_days', 'unique_months']
            
            # è®¡ç®—æ—¶é—´è·¨åº¦ï¼ˆæœˆä»½ï¼‰
            combo_analysis['months_span'] = (
                (combo_analysis['last_date'].dt.year - combo_analysis['first_date'].dt.year) * 12 + 
                (combo_analysis['last_date'].dt.month - combo_analysis['first_date'].dt.month) + 1
            )
            
            # è®¡ç®—è¦†ç›–ç‡
            combo_analysis['coverage_rate'] = (combo_analysis['unique_months'] / combo_analysis['months_span'] * 100).round(1)
            
            print(f"å…³é”®è¯-åŸå¸‚ç»„åˆæ€»æ•°: {len(combo_analysis)}")
            print(f"å¹³å‡æ—¶é—´è·¨åº¦: {combo_analysis['months_span'].mean():.1f} ä¸ªæœˆ")
            print(f"å¹³å‡è¦†ç›–ç‡: {combo_analysis['coverage_rate'].mean():.1f}%")
            
            # æ˜¾ç¤ºè¦†ç›–ç‡åˆ†å¸ƒ
            print("\nè¦†ç›–ç‡åˆ†å¸ƒ:")
            coverage_ranges = [
                (0, 50, "ä½è¦†ç›– (0-50%)"),
                (50, 80, "ä¸­ç­‰è¦†ç›– (50-80%)"),
                (80, 95, "é«˜è¦†ç›– (80-95%)"),
                (95, 100, "æé«˜è¦†ç›– (95-100%)")
            ]
            
            for min_rate, max_rate, label in coverage_ranges:
                count = len(combo_analysis[
                    (combo_analysis['coverage_rate'] >= min_rate) & 
                    (combo_analysis['coverage_rate'] <= max_rate)
                ])
                percentage = count / len(combo_analysis) * 100
                print(f"  {label}: {count} ä¸ªç»„åˆ ({percentage:.1f}%)")
            
            # æ˜¾ç¤ºæ—¶é—´è·¨åº¦æœ€é•¿å’Œæœ€çŸ­çš„ç»„åˆ
            print(f"\næ—¶é—´è·¨åº¦æœ€é•¿çš„ç»„åˆ:")
            longest = combo_analysis.nlargest(3, 'months_span')
            for _, row in longest.iterrows():
                print(f"  {row['keyword']} - {row['city_name']}: {row['months_span']} ä¸ªæœˆ "
                      f"({row['first_date'].strftime('%Y-%m')} åˆ° {row['last_date'].strftime('%Y-%m')})")
            
            print(f"\næ—¶é—´è·¨åº¦æœ€çŸ­çš„ç»„åˆ:")
            shortest = combo_analysis.nsmallest(3, 'months_span')
            for _, row in shortest.iterrows():
                print(f"  {row['keyword']} - {row['city_name']}: {row['months_span']} ä¸ªæœˆ "
                      f"({row['first_date'].strftime('%Y-%m')} åˆ° {row['last_date'].strftime('%Y-%m')})")
            
            return combo_analysis
            
        except Exception as e:
            print(f"æ•°æ®è¦†ç›–åˆ†æå¤±è´¥: {e}")
            return None

    def generate_summary_report(self, df, monthly_data):
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        try:
            report = []
            report.append("=" * 80)
            report.append("æœˆåº¦æ•°æ®ç»Ÿè®¡æŠ¥å‘Š")
            report.append("=" * 80)

            # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
            report.append(f"åŸå§‹æ•°æ®æ€»è¡Œæ•°: {len(df):,}")
            report.append(f"æœˆåº¦æ•°æ®æ€»è¡Œæ•°: {len(monthly_data):,}")
            report.append(f"å…³é”®è¯æ•°é‡: {df['keyword'].nunique()}")
            report.append(f"åŸå¸‚æ•°é‡: {df['city_name'].nunique()}")
            report.append(f"å…³é”®è¯-åŸå¸‚ç»„åˆæ•°: {len(df[['keyword', 'city_name']].drop_duplicates())}")

            # æ—¶é—´èŒƒå›´
            date_range = f"{df['date'].min().strftime('%Y-%m-%d')} åˆ° {df['date'].max().strftime('%Y-%m-%d')}"
            report.append(f"æ•°æ®æ—¶é—´èŒƒå›´: {date_range}")

            # æ•°æ®å®Œæ•´æ€§ç»Ÿè®¡
            if 'has_data' in monthly_data.columns:
                total_records = len(monthly_data)
                records_with_data = monthly_data['has_data'].sum()
                coverage_rate = records_with_data / total_records * 100
                report.append(f"æœˆåº¦æ•°æ®è¦†ç›–ç‡: {coverage_rate:.1f}% ({records_with_data:,}/{total_records:,})")

            # æŒ‰å…³é”®è¯ç»Ÿè®¡
            report.append("\n" + "=" * 50)
            report.append("æŒ‰å…³é”®è¯ç»Ÿè®¡:")
            report.append("=" * 50)
            
            for keyword in df['keyword'].unique():
                keyword_data = df[df['keyword'] == keyword]
                keyword_monthly = monthly_data[monthly_data['keyword'] == keyword]
                
                report.append(f"\nå…³é”®è¯: {keyword}")
                report.append(f"  åŸå§‹æ•°æ®ç‚¹æ•°: {len(keyword_data):,}")
                report.append(f"  æœˆåº¦è®°å½•æ•°: {len(keyword_monthly):,}")
                report.append(f"  åŸå¸‚æ•°é‡: {keyword_data['city_name'].nunique()}")
                report.append(f"  æ—¶é—´èŒƒå›´: {keyword_data['date'].min().strftime('%Y-%m-%d')} åˆ° {keyword_data['date'].max().strftime('%Y-%m-%d')}")
                
                if 'has_data' in keyword_monthly.columns:
                    keyword_coverage = keyword_monthly['has_data'].sum() / len(keyword_monthly) * 100
                    report.append(f"  æ•°æ®è¦†ç›–ç‡: {keyword_coverage:.1f}%")
                
                if 'pc_mobile_index_æœˆåº¦å‡å€¼' in keyword_monthly.columns:
                    avg_index = keyword_monthly['pc_mobile_index_æœˆåº¦å‡å€¼'].mean()
                    if not pd.isna(avg_index):
                        report.append(f"  å¹³å‡æœˆåº¦PC+ç§»åŠ¨æŒ‡æ•°: {avg_index:.2f}")

            # æŒ‰å¹´ä»½ç»Ÿè®¡
            report.append("\n" + "=" * 50)
            report.append("æŒ‰å¹´ä»½ç»Ÿè®¡:")
            report.append("=" * 50)
            
            for year in sorted(monthly_data['year'].unique()):
                year_data = monthly_data[monthly_data['year'] == year]
                if 'has_data' in year_data.columns:
                    year_coverage = year_data['has_data'].sum() / len(year_data) * 100
                    report.append(f"{year}å¹´: è¦†ç›–ç‡ {year_coverage:.1f}% ({year_data['has_data'].sum():,}/{len(year_data):,})")

            # ç¼ºå¤±æ•°æ®åˆ†æ
            if 'has_data' in monthly_data.columns:
                missing_data = monthly_data[monthly_data['has_data'] == False]
                if len(missing_data) > 0:
                    report.append(f"\nç¼ºå¤±æ•°æ®åˆ†æ:")
                    report.append(f"ç¼ºå¤±è®°å½•æ€»æ•°: {len(missing_data):,}")
                    
                    # æŒ‰å…³é”®è¯-åŸå¸‚ç»„åˆç»Ÿè®¡ç¼ºå¤±æƒ…å†µ
                    missing_by_combo = missing_data.groupby(['keyword', 'city_name']).size().sort_values(ascending=False)
                    report.append(f"ç¼ºå¤±æœ€å¤šçš„å…³é”®è¯-åŸå¸‚ç»„åˆ (å‰10):")
                    for (keyword, city), count in missing_by_combo.head(10).items():
                        report.append(f"  {keyword} - {city}: {count} ä¸ªæœˆ")

            report.append("\n" + "=" * 80)

            return "\n".join(report)

        except Exception as e:
            print(f"ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šå¤±è´¥: {e}")
            return "ç»Ÿè®¡æŠ¥å‘Šç”Ÿæˆå¤±è´¥"

    def save_results(self, monthly_data, report):
        """ä¿å­˜ç»“æœ"""
        try:
            # ä¿å­˜æœˆåº¦æ•°æ®
            monthly_file = os.path.join(self.output_dir, "monthly_aggregated_data.xlsx")
            
            # åˆ›å»ºExcelæ–‡ä»¶ï¼ŒåŒ…å«å¤šä¸ªå·¥ä½œè¡¨
            with pd.ExcelWriter(monthly_file, engine='openpyxl') as writer:
                # ä¿å­˜å®Œæ•´æ•°æ®
                monthly_data.to_excel(writer, sheet_name='å®Œæ•´æœˆåº¦æ•°æ®', index=False)
                
                # ä¿å­˜åªæœ‰æ•°æ®çš„è®°å½•
                if 'has_data' in monthly_data.columns:
                    data_only = monthly_data[monthly_data['has_data'] == True]
                    data_only.to_excel(writer, sheet_name='æœ‰æ•°æ®æœˆåº¦è®°å½•', index=False)
                    
                    # ä¿å­˜ç¼ºå¤±æ•°æ®è®°å½•
                    missing_only = monthly_data[monthly_data['has_data'] == False]
                    missing_only.to_excel(writer, sheet_name='ç¼ºå¤±æ•°æ®è®°å½•', index=False)
                
                # ä¿å­˜ç»Ÿè®¡æ‘˜è¦
                summary_stats = self.create_summary_statistics(monthly_data)
                summary_stats.to_excel(writer, sheet_name='ç»Ÿè®¡æ‘˜è¦', index=False)
            
            print(f"æœˆåº¦æ•°æ®å·²ä¿å­˜åˆ°: {monthly_file}")

            # åŒæ—¶ä¿å­˜CSVæ ¼å¼ï¼ˆå®Œæ•´æ•°æ®ï¼‰
            csv_file = os.path.join(self.output_dir, "monthly_aggregated_data.csv")
            monthly_data.to_csv(csv_file, index=False, encoding='utf-8-sig')
            print(f"æœˆåº¦æ•°æ®å·²ä¿å­˜åˆ°: {csv_file}")

            # ä¿å­˜ä¸º DTA æ–‡ä»¶
            try:
                monthly_file_dta = os.path.join(self.output_dir, "monthly_aggregated_data.dta")
                # å¤„ç†åˆ—åé•¿åº¦é™åˆ¶
                monthly_data_for_stata = monthly_data.copy()
                monthly_data_for_stata.columns = [col[:32] for col in monthly_data_for_stata.columns]
                monthly_data_for_stata.to_stata(monthly_file_dta, version=118)
                print(f"æœˆåº¦æ•°æ®å·²ä¿å­˜åˆ°: {monthly_file_dta}")
            except Exception as e:
                print(f"ä¿å­˜DTAæ–‡ä»¶å¤±è´¥: {e}")

            # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
            report_file = os.path.join(self.output_dir, "monthly_report.txt")
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

            return True

        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return False

    def create_summary_statistics(self, monthly_data):
        """åˆ›å»ºç»Ÿè®¡æ‘˜è¦"""
        try:
            summary_list = []
            
            # æŒ‰å…³é”®è¯ç»Ÿè®¡
            if 'has_data' in monthly_data.columns:
                keyword_stats = monthly_data.groupby('keyword').agg({
                    'city_name': 'nunique',
                    'year_month': 'nunique',
                    'has_data': ['sum', 'count']
                }).round(2)
                
                keyword_stats.columns = ['åŸå¸‚æ•°', 'æœˆä»½æ•°', 'æœ‰æ•°æ®æœˆä»½æ•°', 'æ€»æœˆä»½æ•°']
                keyword_stats['æ•°æ®è¦†ç›–ç‡'] = (keyword_stats['æœ‰æ•°æ®æœˆä»½æ•°'] / keyword_stats['æ€»æœˆä»½æ•°'] * 100).round(1)
                keyword_stats = keyword_stats.reset_index()
                
                return keyword_stats
            else:
                return pd.DataFrame()
            
        except Exception as e:
            print(f"åˆ›å»ºç»Ÿè®¡æ‘˜è¦å¤±è´¥: {e}")
            return pd.DataFrame()

    def process(self):
        """ä¸»å¤„ç†æµç¨‹"""
        print("å¼€å§‹å¤„ç†æœˆåº¦æ•°æ®ç»Ÿè®¡...")

        # 1. åŠ è½½æ•°æ®
        df = self.load_data()
        if df is None:
            return False

        # 2. é¢„å¤„ç†æ•°æ®
        df = self.preprocess_data(df)
        if df is None:
            return False

        # 3. åˆ†ææ•°æ®è¦†ç›–æƒ…å†µ
        coverage_analysis = self.analyze_data_coverage(df)

        # 4. åˆ›å»ºå®Œæ•´çš„æœˆåº¦æ•°æ®
        monthly_data = self.create_complete_monthly_data(df)
        if monthly_data is None:
            return False

        # 5. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        report = self.generate_summary_report(df, monthly_data)

        # 6. ä¿å­˜ç»“æœ
        success = self.save_results(monthly_data, report)

        if success:
            print("\nå¤„ç†å®Œæˆï¼")
            print(report)

        return success


# ä½¿ç”¨ç¤ºä¾‹
def main():
    # é…ç½®æ–‡ä»¶è·¯å¾„
    input_file = "/Users/auroral/ProjectDevelopment/BaiduIndexHunter/unique_sample_data.csv"
    output_directory = "/Users/auroral/ProjectDevelopment/BaiduIndexHunter/baidu-index-hunter-backend/data_progress"

    # åˆ›å»ºå¤„ç†å™¨å®ä¾‹
    aggregator = MonthlyDataAggregator(input_file, output_directory)

    # æ‰§è¡Œå¤„ç†
    success = aggregator.process()

    if success:
        print("\nâœ… æœˆåº¦æ•°æ®ç»Ÿè®¡å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {output_directory}")
        print("ğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
        print("   - monthly_aggregated_data.xlsx (Excelæ ¼å¼ï¼ŒåŒ…å«å¤šä¸ªå·¥ä½œè¡¨)")
        print("   - monthly_aggregated_data.csv (CSVæ ¼å¼)")
        print("   - monthly_aggregated_data.dta (Stataæ ¼å¼)")
        print("   - monthly_report.txt (ç»Ÿè®¡æŠ¥å‘Š)")
    else:
        print("\nâŒ å¤„ç†å¤±è´¥ï¼")


if __name__ == "__main__":
    main()


# ç®€åŒ–ç‰ˆæœ¬çš„å‡½æ•°ï¼Œè€ƒè™‘æ¯ä¸ªç»„åˆçš„å®é™…æ—¶é—´è·¨åº¦
def simple_monthly_aggregation_with_individual_ranges(df):
    """
    æ”¹è¿›çš„ç®€åŒ–æœˆåº¦èšåˆå‡½æ•°ï¼Œä¸ºæ¯ä¸ªå…³é”®è¯-åŸå¸‚ç»„åˆåˆ›å»ºå…¶å„è‡ªçš„å®Œæ•´æ—¶é—´èŒƒå›´

    Args:
        df: åŒ…å«æ—¥æœŸå’ŒæŒ‡æ•°æ•°æ®çš„DataFrame

    Returns:
        complete_monthly_data: å®Œæ•´çš„æœˆåº¦æ•°æ®ï¼ŒåŒ…å«ç¼ºå¤±æœˆä»½
    """
    # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
    df['date'] = pd.to_datetime(df['date'])
    df['year_month'] = df['date'].dt.strftime('%Y-%m')
    
    # è·å–æ¯ä¸ªå…³é”®è¯-åŸå¸‚ç»„åˆçš„æ—¶é—´èŒƒå›´
    combo_ranges = df.groupby(['keyword', 'city_code', 'city_name'])['date'].agg(['min', 'max']).reset_index()
    
    # ä¸ºæ¯ä¸ªç»„åˆåˆ›å»ºå®Œæ•´çš„æœˆä»½æ¨¡æ¿
    template_data = []
    for _, combo in combo_ranges.iterrows():
        # åˆ›å»ºä»æœ€å°æ—¥æœŸåˆ°æœ€å¤§æ—¥æœŸçš„æ‰€æœ‰æœˆä»½
        min_date = combo['min'].replace(day=1)
        max_date = combo['max'].replace(day=1)
        
        date_range = pd.date_range(start=min_date, end=max_date, freq='MS')
        year_months = [date.strftime('%Y-%m') for date in date_range]
        
        for ym in year_months:
            template_data.append({
                'keyword': combo['keyword'],
                'city_code': combo['city_code'],
                'city_name': combo['city_name'],
                'year_month': ym
            })
    
    template_df = pd.DataFrame(template_data)
    
    # èšåˆå®é™…æ•°æ®
    monthly_aggregated = df.groupby(['keyword', 'city_code', 'city_name', 'year_month']).agg({
        'pc_mobile_index': ['sum', 'mean', 'count'],
        'mobile_index': ['sum', 'mean', 'count'],
        'pc_index': ['sum', 'mean', 'count']
    }).reset_index()
    
    # å¤„ç†åˆ—å
    new_columns = ['keyword', 'city_code', 'city_name', 'year_month']
    for col in ['pc_mobile_index', 'mobile_index', 'pc_index']:
        new_columns.extend([f'{col}_æœˆåº¦æ€»å’Œ', f'{col}_æœˆåº¦å‡å€¼', f'{col}_æ•°æ®ç‚¹æ•°'])
    
    monthly_aggregated.columns = new_columns
    
    # ä¸æ¨¡æ¿åˆå¹¶
    complete_monthly_data = template_df.merge(monthly_aggregated, 
                                            on=['keyword', 'city_code', 'city_name', 'year_month'],
                                            how='left')
    
    # æ·»åŠ æ•°æ®æ ‡è¯†
    complete_monthly_data['has_data'] = complete_monthly_data['pc_mobile_index_æ•°æ®ç‚¹æ•°'].notna()
    
    print(f"å®Œæ•´æœˆåº¦æ•°æ®åˆ›å»ºå®Œæˆ:")
    print(f"  æ€»è®°å½•æ•°: {len(complete_monthly_data)}")
    print(f"  æœ‰æ•°æ®è®°å½•æ•°: {complete_monthly_data['has_data'].sum()}")
    print(f"  æ•°æ®è¦†ç›–ç‡: {complete_monthly_data['has_data'].sum()/len(complete_monthly_data)*100:.1f}%")
    
    return complete_monthly_data